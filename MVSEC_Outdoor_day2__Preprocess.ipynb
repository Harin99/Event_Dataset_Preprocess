{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcmJL2G6ZzvFEf539+dIB/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harin99/Event_Dataset_Preprocess/blob/main/MVSEC_Outdoor_day2__Preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q4NJ9yDzq31w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import h5py\n",
        "import pickle\n",
        "import torch "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = h5py.File('/share/data/outdoor_day2/outdoor_day2_data.hdf5', 'r')\n",
        "data_gt = h5py.File('/share/data/outdoor_day2/outdoor_day2_gt.hdf5', 'r')\n",
        "processed_data = h5py.File('/share/data/outdoor_day2/proceseed_data.hdf5', 'r')"
      ],
      "metadata": {
        "id": "ftV4kxcLsJof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.keys())\n",
        "print(data_gt.keys())\n",
        "print(processed_data.keys())"
      ],
      "metadata": {
        "id": "TVUEvy7MsJq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flow Data & Timestamp Extraction "
      ],
      "metadata": {
        "id": "vcO3vsqRq6Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def traverse_datasets(hdf_file):\n",
        "\n",
        "    def h5py_dataset_iterator(g, prefix=''):\n",
        "        for key in g.keys():\n",
        "            item = g[key]\n",
        "            path = f'{prefix}/{key}'\n",
        "            if isinstance(item, h5py.Dataset): # test for dataset\n",
        "                yield (path, item)\n",
        "            elif isinstance(item, h5py.Group): # test for group (go down)\n",
        "                yield from h5py_dataset_iterator(item, path)\n",
        "\n",
        "    for path, what in h5py_dataset_iterator(hdf_file):\n",
        "        yield path, what"
      ],
      "metadata": {
        "id": "3rc2rBbOq7Px"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with h5py.File('/share/data/outdoor_day2/outdoor_day2_gt.hdf5', 'r') as f:\n",
        "    # get a h5py dataset object\n",
        "    flow_dist = f['davis']['left']['flow_dist']\n",
        "    print('flow_dist dtype :', flow_dist.dtype, '\\n flow_dist shape :', flow_dist.shape)\n",
        "    flow_dist_ts = f['davis']['left']['flow_dist_ts']\n",
        "    print('flow_dist_ts dtype : ', flow_dist_ts.dtype, '\\n flow_dist_ts shape :', flow_dist_ts.shape)\n",
        "    \n",
        "    # get the all data \n",
        "    flow_dist_data = flow_dist[:]\n",
        "    flow_dist_ts_data = flow_dist_ts[:]"
      ],
      "metadata": {
        "id": "346uWMpNq83N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Event Data Extraction "
      ],
      "metadata": {
        "id": "-AYB3KtArzx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with h5py.File('/share/data/outdoor_day2//outdoor_day2_data.hdf5', 'r') as f:\n",
        "    # get a h5py dataset object\n",
        "    events = f['davis']['left']['events']\n",
        "    print('events dtype :', events.dtype, '\\n events shape :', events.shape)\n",
        "    \n",
        "    # get the all data \n",
        "    # ( x, y, ts, p )\n",
        "    event_data = events[:]"
      ],
      "metadata": {
        "id": "YNVRGpJMq9m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optical Flow Timestamp에 대응되는 Event .npy Data 생성 "
      ],
      "metadata": {
        "id": "OTaaB1UasSXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optical Flow : 20 Hz (Original) \\\n",
        "optical flow timestamp : (12197,) \\\n",
        "Event timestamp : (466410069, 4) \\\n",
        "\\\n",
        "생성 방법 : [(t-1) optical flow ts] ~ [(t) optical flow ts] = (t) Event .npy \\\n",
        "첫번째 데이터 : 이전 모든 Event data ~ flow timestamp 까지의 모든 데이터를 넣기때문에 사용할 수 없는 더미 데이터 "
      ],
      "metadata": {
        "id": "rURy39AFsSaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "events_list = []\n",
        "saved_events_path = '/share/data/mvsec_outdoor_day_2_20Hz/outdoor_day_2/davis/left/events/'\n",
        "saved_flow_path = '/share/data/mvsec_outdoor_day_2_20Hz/outdoor_day_2/optical_flow/'\n",
        "\n",
        "for i, ts in enumerate(flow_dist_ts_data):\n",
        "    if i == 0:\n",
        "        # event_data[:, 2] : event timestamp \n",
        "        inner = ((ts - event_data[:, 2]) < 0.005 ) & (0 < (ts - event_data[:, 2]))\n",
        "        inner = np.array(inner, dtype = float)\n",
        "        inner_idx = np.nonzero(inner)[0][-1]\n",
        "        events = event_data[:inner_idx+1, :]\n",
        "\n",
        "        # Print\n",
        "        print(events.shape)\n",
        "        print(\"%s : %f ~ %f\" %(str(i), events[0, 2], events[-1, 2]))\n",
        "\n",
        "        prev_ts = inner_idx\n",
        "        # Data Save\n",
        "        np.save(saved_events_path + str(int(i)), events)\n",
        "    \n",
        "    else:\n",
        "        # event_data[:, 2] : event timestamp \n",
        "        inner = ((ts - event_data[:, 2]) < 0.005 ) & (0 < (ts - event_data[:, 2]))\n",
        "        inner = np.array(inner, dtype = float)\n",
        "        inner_idx = np.nonzero(inner)[0][-1]\n",
        "        events = event_data[prev_ts+1:inner_idx+1, :]\n",
        "\n",
        "        # Print\n",
        "        print(events.shape)\n",
        "        print(\"%s : %f ~ %f\" %(str(i), events[0, 2], events[-1, 2]))\n",
        "\n",
        "        prev_ts = inner_idx\n",
        "        # Data Save\n",
        "        np.save(saved_events_path + str(int(i)), events)\n",
        "    "
      ],
      "metadata": {
        "id": "FwQKRpx5q-ms"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4HDujqrRsY2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optical Flow .npy Data 생성 "
      ],
      "metadata": {
        "id": "Q1oEWt_XsZQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, flow in enumerate(flow_dist_data):\n",
        "    # Data 저장 \n",
        "    print(flow.shape)\n",
        "    np.save(saved_flow_path + str(int(i)), flow)"
      ],
      "metadata": {
        "id": "Tlc4IDQqsWdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## flowtimestamps.txt 생성 \n",
        "E-Raft Model에서는 해당 text 파일을 이용하여 data align을 진행함 "
      ],
      "metadata": {
        "id": "ryGanByysbnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_ts_path = '/share/data/mvsec_outdoor_day_2_20Hz/outdoor_day_2/'\n",
        "np.savetxt(saved_ts_path + 'timestamps_flow.txt', flow_dist_ts_data)"
      ],
      "metadata": {
        "id": "6eU0Hr3-sWgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 최종 생성된 Data 확인 "
      ],
      "metadata": {
        "id": "p6dD3HYmsdsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event_path = '/share/data/mvsec_outdoor_day_2_20Hz/outdoor_day_2/davis/left/events'\n",
        "flow_path = '/share/data/mvsec_outdoor_day_2_20Hz/outdoor_day_2/optical_flow'\n",
        "flow_ts_path = '/share/dataa/mvsec_outdoor_day_2_20Hz/outdoor_day_2/timestamps_flow.txt'"
      ],
      "metadata": {
        "id": "FJ794nb3sWi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event_list = os.listdir(event_path)\n",
        "event_list[-1]"
      ],
      "metadata": {
        "id": "60c9PxYdsWlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flow_list = os.listdir(flow_path)\n",
        "len(flow_list)\n",
        "flow_list[-1]"
      ],
      "metadata": {
        "id": "jbBz4q7OsWoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flow_ts = np.loadtxt(flow_ts_path)\n",
        "len(flow_ts)\n",
        "flow_ts[-1]"
      ],
      "metadata": {
        "id": "yQuklIlesWrS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}