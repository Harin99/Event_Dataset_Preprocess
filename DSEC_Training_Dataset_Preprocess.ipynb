{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0c0244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import os\n",
    "import urllib\n",
    "import shutil\n",
    "from typing import Union\n",
    "import zipfile\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692343f",
   "metadata": {},
   "source": [
    "## 1. DSEC Training Dataset Download \n",
    "1. Dataset Page Access \n",
    "2. Generate Directory that save the dataset \n",
    "3. Download & Unzip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dab4e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SEQUENCES = ['thun_00_a', 'zurich_city_01_a', 'zurich_city_02_a', 'zurich_city_02_c', 'zurich_city_02_d', \n",
    "                   'zurich_city_02_e', 'zurich_city_03_a', 'zurich_city_05_a', 'zurich_city_05_b', 'zurich_city_06_a', \n",
    "                   'zurich_city_07_a', 'zurich_city_08_a', 'zurich_city_09_a', 'zurich_city_10_a', 'zurich_city_10_b',\n",
    "                  'zurich_city_11_a', 'zurich_city_11_b', 'zurich_city_11_c']\n",
    "\n",
    "BASE_TRAIN_URL = 'https://download.ifi.uzh.ch/rpg/DSEC/train/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14b56ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url: str, filepath: Path, skip: bool=True) -> bool:\n",
    "    with open(str(filepath), 'wb') as fl:\n",
    "        response = get(url)\n",
    "        fl.write(response.content)\n",
    "\n",
    "def unzip(file_path, output_path):\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_path)\n",
    "        os.remove(file_path)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/share/data/train'\n",
    "\n",
    "for seq_name in TRAIN_SEQUENCES:\n",
    "    # Directory Generation \n",
    "    seq_path = output_dir + '/' + seq_name\n",
    "    os.makedirs(seq_path, exist_ok = True)\n",
    "    os.makedirs(seq_path + '/' + 'events_left')\n",
    "    os.makedirs(seq_path + '/' + 'optical_flow')\n",
    "    \n",
    "    # flow timestamp path \n",
    "    flow_name = seq_name + '_optical_flow_forward_timestamps.txt'\n",
    "    flow_path = BASE_TRAIN_URL + seq_name + '/' + flow_name\n",
    "    flow_file = seq_path + '/' + 'train_forward_flow_timestamps.txt'\n",
    "    download(flow_path, flow_file)\n",
    "    \n",
    "    # event left path \n",
    "    event_name = seq_name + '_events_left.zip'\n",
    "    event_path = BASE_TRAIN_URL + seq_name + '/' + event_name\n",
    "    event_file = seq_path + '/' + 'events_left.zip'\n",
    "    download(event_path, event_file)\n",
    "    zip_output_path = seq_path + '/events_left/'\n",
    "    unzip(event_file, zip_output_path)\n",
    "    \n",
    "    # image timestamps path \n",
    "    image_name = seq_name + '_image_timestamps.txt'\n",
    "    image_path = BASE_TRAIN_URL + seq_name + '/' + image_name\n",
    "    image_file = seq_path + '/' + 'image_timestamps.txt'\n",
    "    download(image_path, image_file)\n",
    "    \n",
    "    # optical flow \n",
    "    flow_name = seq_name + '_optical_flow_forward_event.zip'\n",
    "    flow_path = BASE_TRAIN_URL + seq_name + '/' + flow_name\n",
    "    flow_file = seq_path + '/' + 'optical_flow.zip'\n",
    "    download(flow_path, flow_file)\n",
    "    zip_output_path = seq_path + '/optical_flow/'\n",
    "    unzip(flow_file, zip_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flow_path)\n",
    "print(event_path)\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f01943",
   "metadata": {},
   "source": [
    "## 2. Training Dataset ( flowtimestamp.txt -> .csv ) \n",
    "- File Index matching with Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358aac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/share/data/train/'\n",
    "train_list = os.listdir(train_dir)\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce88583",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in train_list:\n",
    "    flow_ts_path = train_dir + name + '/train_forward_flow_timestamps.txt'\n",
    "    image_ts_path = train_dir + name + '/image_timestamps.txt'\n",
    "    flow_ts = open(flow_ts_path, 'r')\n",
    "    flow_ts = flow_ts.readlines()\n",
    "    image_ts = np.loadtxt(image_ts_path)\n",
    "    # DataFrame 생성 \n",
    "    df = pd.DataFrame(columns = {'# from_timestamp_us', 'to_timestamp_us', 'file_index'})\n",
    "    for i in range(len(flow_ts)-1):\n",
    "        from_us = int(flow_ts[i+1].split(',')[0])\n",
    "        to_us = int(flow_ts[i+1].split(',')[1])\n",
    "        image_ts_list = list(image_ts)\n",
    "        idx = image_ts_list.index(from_us)\n",
    "        df.loc[i] = [from_us, to_us, idx]\n",
    "    # 생성된 Flow dataframe -> csv 로 save하기 \n",
    "    output_dir = train_dir + name + '/train_forward_flow_timestamps.csv'\n",
    "    df.to_csv(output_dir, index = False)\n",
    "    ## Total 개수 합계\n",
    "    csv = pd.read_csv(output_dir)\n",
    "    count += len(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "578793c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## csv file Colume Order Change \n",
    "\n",
    "for name in train_list:\n",
    "    output_dir = train_dir + name + '/train_forward_flow_timestamps.csv'\n",
    "    csv = pd.read_csv(output_dir)\n",
    "    csv = csv.rename(columns={'# from_timestamp_us': 'file_index', 'file_index': '# from_timestamp_us'})\n",
    "    csv.to_csv(output_dir, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec72d3",
   "metadata": {},
   "source": [
    "## 참고\n",
    "- 위에서 다운받은 DSEC Training dataset sequence 에는 연속적이지않은 데이터가 포함되어있다. \\\n",
    "- 따라서 E-Raft Network에서 데이터셋을 불러올 때 연속적인 데이터를 불러올 수 있도록, 연속적이지않은 Sequence 의 경우에는 이를 또 세부적으로 연속적인 데이터들만 sub-sequence 로 분리하여 새로운 폴더를 생성해줄 필요가 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ae8af",
   "metadata": {},
   "source": [
    "## 3. Non-sequential Sequence Dataset Preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "166b6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not release "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2455df74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
